{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNteB+6fPCiYTOm1thQyQu0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vYMIQoWL0MmX"},"outputs":[],"source":["!pip install tensorflow\n","!pip install numpy\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"icD2qwQr0OQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, regularizers, callbacks\n","\n","# ===============================\n","# CONFIG\n","# ===============================\n","# Adjust these paths as per your Colab setup\n","!cp -r /content/drive/MyDrive/Urdu_letter_handwriting_dataset /content/datasets_local\n","DATASET_PATH  = \"/content/datasets_local\"\n","SAVE_PATH = \"/content/drive/MyDrive/vgg1_urdu_custom.keras\" # Using .keras format\n","IMG_SIZE = (128, 128)\n","BATCH_SIZE = 64\n","VAL_SPLIT = 0.2\n","SEED = 42"],"metadata":{"id":"9BnTb7ap0Z1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# ===============================\n","# DATA PREPROCESSING & LOADING\n","# ===============================\n","def preprocess(image, label):\n","    image = tf.cast(image, tf.float32) / 255.0\n","    # IMPORTANT: Invert colors (White bg/Black text -> Black bg/White text)\n","    # This helps the model focus on the letter strokes as features (1s) rather than empty space.\n","    image = 1.0 - image\n","    return image, label\n","\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    DATASET_PATH,\n","    labels=\"inferred\",\n","    label_mode=\"int\",\n","    batch_size=BATCH_SIZE,\n","    image_size=IMG_SIZE,\n","    color_mode=\"grayscale\",\n","    shuffle=True,\n","    seed=SEED,\n","    validation_split=VAL_SPLIT,\n","    subset=\"training\"\n",")\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","    DATASET_PATH,\n","    labels=\"inferred\",\n","    label_mode=\"int\",\n","    batch_size=BATCH_SIZE,\n","    image_size=IMG_SIZE,\n","    color_mode=\"grayscale\",\n","    shuffle=True,\n","    seed=SEED,\n","    validation_split=VAL_SPLIT,\n","    subset=\"validation\"\n",")\n","\n","train_ds = train_ds.map(preprocess).prefetch(buffer_size=tf.data.AUTOTUNE)\n","val_ds = val_ds.map(preprocess).prefetch(buffer_size=tf.data.AUTOTUNE)\n","\n","# Data Augmentation (Kept light to preserve letter structure)\n","data_augmentation = tf.keras.Sequential([\n","    layers.RandomRotation(0.05),\n","    layers.RandomZoom(0.05),\n","    layers.RandomTranslation(0.05, 0.05),\n","])\n","\n","# =======================================\n","# CUSTOM VGG-STYLE ARCHITECTURE (From Scratch)\n","# =======================================\n","def build_custom_vgg(num_classes):\n","    inputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 1))\n","\n","    # Augmentation inside the model\n","    x = data_augmentation(inputs)\n","\n","    # --- Block 1: Capture fine details (edges/strokes) ---\n","    x = layers.Conv2D(32, (3, 3), padding=\"same\", use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","    x = layers.Conv2D(32, (3, 3), padding=\"same\", use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","    x = layers.MaxPooling2D((2, 2))(x)\n","    x = layers.Dropout(0.2)(x) # Light dropout\n","\n","    # --- Block 2: Capture shapes (curves/dots) ---\n","    x = layers.Conv2D(64, (3, 3), padding=\"same\", use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","    x = layers.Conv2D(64, (3, 3), padding=\"same\", use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","    x = layers.MaxPooling2D((2, 2))(x)\n","    x = layers.Dropout(0.25)(x)\n","\n","    # --- Block 3: Capture complex features (letters) ---\n","    x = layers.Conv2D(128, (3, 3), padding=\"same\", use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","    x = layers.Conv2D(128, (3, 3), padding=\"same\", use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","    x = layers.MaxPooling2D((2, 2))(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    # --- Block 4: Deep features ---\n","    x = layers.Conv2D(256, (3, 3), padding=\"same\", use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.ReLU()(x)\n","    x = layers.MaxPooling2D((2, 2))(x)\n","    x = layers.Dropout(0.4)(x)\n","\n","    # --- Classifier ---\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dense(256, activation=\"relu\")(x)\n","    x = layers.Dropout(0.5)(x) # Heavy dropout before final layer\n","    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n","\n","    model = models.Model(inputs, outputs, name=\"Urdu_VGG_Custom\")\n","\n","    # Using AdamW (Adam with Weight Decay) is often better for generalization\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"]\n","    )\n","\n","    return model\n","\n","# =======================================\n","# TRAINING\n","# =======================================\n","\n","# Get number of classes dynamically\n","num_classes = len(os.listdir(DATASET_PATH))\n","print(f\"Detected {num_classes} Classes\")\n","\n","model = build_custom_vgg(num_classes)\n","model.summary()\n","\n","# KEY FIX: Learning Rate Scheduler\n","# If val_loss doesn't improve for 3 epochs, reduce LR by factor of 0.5.\n","# This prevents the \"crashing\" accuracy you saw in your logs.\n","reduce_lr = callbacks.ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.5,\n","    patience=3,\n","    min_lr=1e-6,\n","    verbose=1\n",")\n","\n","early_stop = callbacks.EarlyStopping(\n","    monitor=\"val_loss\",\n","    patience=8,\n","    restore_best_weights=True,\n","    verbose=1\n",")\n","\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=40, # increased epochs as we have LR scheduler now\n","    callbacks=[early_stop, reduce_lr]\n",")\n","\n","# Save in modern keras format\n","model.save(SAVE_PATH)\n","print(\"Model saved at:\", SAVE_PATH)"],"metadata":{"id":"xBwBoO0Z0ctr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load and test model"],"metadata":{"id":"n4ieobdf1ZCM"}},{"cell_type":"code","source":["!pip install matplotlib\n","!pip install seaborn\n","!pip install scikit-learn"],"metadata":{"id":"KlrKicTp0hmb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","import os\n","import io\n","from PIL import Image\n","from IPython.display import display, HTML\n","from google.colab import drive\n","\n","# =======================================================================\n","# ⚡ RESUMEABLE SETUP CELL ⚡\n","# Run this every time you reconnect the Colab session.\n","# =======================================================================\n","\n","# 1. Re-Mount Google Drive (Required for model loading)\n","print(\"1. Re-Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","\n","# =======================================================================\n","# 0. CONFIGURATION (IMPORTANT: CHECK THESE PATHS!)\n","# =======================================================================\n","# Path where your best model was saved\n","MODEL_PATH = '/content/drive/MyDrive/vgg1_urdu_custom.keras'\n","\n","# The class names list (33 total) - Use the confirmed list\n","CLASS_NAMES = ['ا', 'آ', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'و', 'ٹ', 'پ', 'چ', 'ڈ', 'ڑ', 'ژ', 'ک', 'گ', 'ہ', 'ی', 'ے']\n","\n","IMG_SIZE = (128, 128) # Must match the training size\n","# =======================================================================\n","\n","\n","# =======================================================================\n","# 1. LOAD THE TRAINED MODEL\n","# =======================================================================\n","print(f\"\\n--- 1. Loading model from: {MODEL_PATH} ---\")\n","try:\n","    model = tf.keras.models.load_model(MODEL_PATH)\n","    print(\"Model loaded successfully!\")\n","    print(f\"Best model validation accuracy (from log): ~99.24%\")\n","except Exception as e:\n","    print(f\"ERROR: Could not load the model. Please check the MODEL_PATH variable.\")\n","    print(f\"Details: {e}\")\n","    # exit()\n","\n","\n","# =======================================================================\n","# 2. IMAGE PREPROCESSING FUNCTION\n","# =======================================================================\n","def preprocess_image_from_bytes(image_bytes):\n","    \"\"\"\n","    Loads, resizes, and preprocesses a single image from its byte content.\n","    Returns: preprocessed image array (1, 128, 128, 1) and raw array for plotting.\n","    \"\"\"\n","    try:\n","        # Load from bytes, convert to grayscale, and resize\n","        img_pil = Image.open(io.BytesIO(image_bytes)).convert('L')\n","        img_resized = img_pil.resize(IMG_SIZE)\n","\n","        # Convert to NumPy array and normalize\n","        img_array_raw = np.array(img_resized, dtype=np.float32) / 255.0\n","\n","        # Expand dimensions for CNN: (128, 128) -> (1, 128, 128, 1)\n","        img_preprocessed = np.expand_dims(img_array_raw, axis=-1)\n","        img_preprocessed = np.expand_dims(img_preprocessed, axis=0)\n","\n","        # Invert colors\n","        img_preprocessed_inverted = 1.0 - img_preprocessed\n","\n","        return img_preprocessed_inverted, img_array_raw\n","\n","    except Exception as e:\n","        print(f\"  [ERROR] Failed to process image: {e}\")\n","        return None, None\n","\n","\n","# =======================================================================\n","# 3. UPLOAD FILES AND BATCH PREDICTION\n","# =======================================================================\n","print(\"\\n--- 2. Uploading Test Images (You can select multiple files) ---\")\n","# This opens the dialog allowing the user to select multiple images.\n","uploaded_files = files.upload()\n","\n","if not uploaded_files:\n","    print(\"No images were uploaded. Exiting prediction.\")\n","else:\n","    num_uploaded = len(uploaded_files)\n","    print(f\"Found {num_uploaded} images to predict.\")\n","\n","    # Initialize list to hold results for final summary\n","    results = []\n","\n","    # Configure Matplotlib for multiple small plots\n","    fig, axes = plt.subplots(num_uploaded, 2, figsize=(10, 5 * num_uploaded))\n","\n","    # Handle case where only one image is found\n","    if num_uploaded == 1:\n","        axes = [[axes[0], axes[1]]] # Wrap in a list for consistent indexing\n","\n","    # Iterate over the uploaded dictionary (key=filename, value=bytes)\n","    for i, (filename, image_bytes) in enumerate(uploaded_files.items()):\n","\n","        # Preprocess the image from its byte content\n","        img_input, img_raw = preprocess_image_from_bytes(image_bytes)\n","\n","        if img_input is None:\n","            continue\n","\n","        # Predict\n","        predictions = model.predict(img_input, verbose=0)\n","\n","        # Get result details\n","        predicted_class_index = np.argmax(predictions[0])\n","        confidence = predictions[0][predicted_class_index] * 100\n","        predicted_char = CLASS_NAMES[predicted_class_index]\n","\n","        results.append({\n","            'File': filename,\n","            'Prediction': predicted_char,\n","            'Confidence': confidence\n","        })\n","\n","        # --- Plotting the result ---\n","        # 1. Original Image Plot\n","        ax_raw = axes[i][0]\n","        ax_raw.imshow(img_raw, cmap='gray', vmin=0, vmax=1)\n","        ax_raw.set_title(f\"Input: {filename}\", fontsize=10)\n","        ax_raw.axis('off')\n","\n","        # 2. Processed Image Plot with Prediction\n","        ax_proc = axes[i][1]\n","        ax_proc.imshow(img_input.squeeze(), cmap='gray', vmin=0, vmax=1)\n","        ax_proc.set_title(f\"Prediction: {predicted_char} ({confidence:.1f}%)\",\n","                          fontsize=10, color='blue')\n","        ax_proc.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # =======================================================================\n","    # 4. FINAL SUMMARY TABLE\n","    # =======================================================================\n","    print(\"\\n--- 4. Batch Prediction Summary ---\")\n","\n","    # Create a simple table summary\n","    html_table = \"<table><thead><tr><th>File Name</th><th>Prediction</th><th>Confidence</th></tr></thead><tbody>\"\n","    for res in results:\n","        color = 'black'\n","        # Highlight low confidence predictions (e.g., below 90%)\n","        if res['Confidence'] < 90.0:\n","            color = 'darkorange'\n","\n","        html_table += f\"<tr><td>{res['File']}</td><td style='font-size: 1.5em;'>{res['Prediction']}</td><td style='color:{color};'>{res['Confidence']:.2f}%</td></tr>\"\n","\n","    html_table += \"</tbody></table>\"\n","    display(HTML(html_table))"],"metadata":{"id":"ID8MDM-g1V7I"},"execution_count":null,"outputs":[]}]}